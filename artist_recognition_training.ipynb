{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88d42d7d",
   "metadata": {},
   "source": [
    "# Artist Recognition — Training\n",
    "\n",
    "In this notebook, we train a neural network, using the Kaggle GPU, to recognize the painter of a given painting. We start with the Kaggle dataset [Best Artworks of All Time](https://www.kaggle.com/datasets/ikarus777/best-artworks-of-all-time?select=resized). Given the **imbalanced data** (some painters are overrepresented), we focus for educational purposes on the **top 3 most represented painters**: Van Gogh, Picasso, and Degas.\n",
    "\n",
    "## Model\n",
    "\n",
    "We use **ResNet-18**, a convolutional neural network with 18 layers. We start with a **pretrained model** and **fine-tune only the last few layers**, while freezing the earlier layers. This is done because early layers learn **generic features** like edges and textures, whereas later layers learn **task-specific features** relevant to our dataset.\n",
    "\n",
    "## Image Preprocessing\n",
    "\n",
    "We standardize the images by:\n",
    "\n",
    "* Resizing them to **224×224 pixels**\n",
    "* Normalizing pixel values by **subtracting the mean and dividing by the standard deviation** for each RGB channel\n",
    "\n",
    "## Data Augmentation\n",
    "\n",
    "To improve generalization and reduce overfitting, we apply the following augmentations:\n",
    "\n",
    "* Randomly flipping the images horizontally  \n",
    "* Randomly rotating them  \n",
    "* Randomly changing brightness, contrast, saturation, and hue\n",
    "\n",
    "## Training Setup\n",
    "\n",
    "* **Loss function:** Cross-entropy with class weighting to address imbalance  \n",
    "* **Optimizer:** Adam  \n",
    "* **Fine-tuned layers:** Last convolutional block (`layer4`) and the fully connected layer (`fc`)  \n",
    "* **Number of epochs:** 20  \n",
    "* **Batch size:** 32  \n",
    "\n",
    "## Results\n",
    "\n",
    "The model is trained on the top 3 painters and evaluated on a validation set. Data augmentation and fine-tuning help improve generalization despite the small dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cfa3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Edgar_Degas', 'Pablo_Picasso', 'Vincent_van_Gogh']\n",
      "Counter({'Vincent_van_Gogh': 877, 'Edgar_Degas': 702, 'Pablo_Picasso': 439})\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import re\n",
    "\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "image_dir = \"./top3_painters\" #directory where the images are located\n",
    "\n",
    "\n",
    "def normalize_artist(name):\n",
    "    # Step 1 — Fix mojibake (latin1 -> utf8)\n",
    "    try:\n",
    "        name = name.encode(\"latin1\").decode(\"utf8\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Step 2 — Normalize accented unicode (ü -> u, é -> e, etc.)\n",
    "    name = unicodedata.normalize(\"NFKD\", name)\n",
    "\n",
    "    # Step 3 — Force everything to pure ASCII\n",
    "    name = name.encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "\n",
    "    return name\n",
    "    \n",
    "import os, re\n",
    "\n",
    "def extract_artist(filename):\n",
    "    name = os.path.splitext(filename)[0]\n",
    "    name = re.sub(r'_\\d+$', '', name)\n",
    "    name = normalize_artist(name)\n",
    "    return name\n",
    "\n",
    "files = os.listdir(image_dir) \n",
    "\n",
    "labels = [extract_artist(file) for file in files]\n",
    "\n",
    "class_counts = Counter(labels)\n",
    "\n",
    "unique_labels = sorted(set(labels))\n",
    "\n",
    "print(unique_labels)\n",
    "print(class_counts)\n",
    "\n",
    "# Create mappings\n",
    "label2idx = {label: i for i, label in enumerate(unique_labels)}\n",
    "idx2label = {i: label for label, i in label2idx.items()}\n",
    "\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(0.2,0.2,0.2,0.1),\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],\n",
    "                         [0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],\n",
    "                         [0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "\n",
    "#To train the model with PyTorch we need to create a dataset class\n",
    "class PaintingDataset(Dataset):\n",
    "    def __init__(self, files, labels, transform):\n",
    "        self.files = files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(os.path.join(image_dir, self.files[idx])).convert(\"RGB\")\n",
    "        img = self.transform(img)\n",
    "\n",
    "        label = label2idx[self.labels[idx]]\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037ec2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "#Split the dataset into train and val\n",
    "train_files, val_files = train_test_split(files, test_size=0.2, random_state=42)\n",
    "train_labels = [extract_artist(f) for f in train_files]\n",
    "val_labels = [extract_artist(f) for f in val_files]\n",
    "\n",
    "#Load the dataset and apply the transformations (standardisation and augmentation)\n",
    "train_dataset = PaintingDataset(train_files, train_labels, train_transform)\n",
    "val_dataset = PaintingDataset(val_files, val_labels, val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "model = resnet18(weights=ResNet18_Weights.DEFAULT) \n",
    "\n",
    "\n",
    "num_classes = len(unique_labels)  # number of painters\n",
    "\n",
    "# Replace the final fully connected layer\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "#If the cuda gpu is available use it (can be done on Kaggle)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "#since the data is unbalanced we rescale the weights\n",
    "weights_tensor = torch.tensor([1.0 / class_counts[label] for label in unique_labels], dtype=torch.float)\n",
    "weights_tensor = weights_tensor.to(device)\n",
    "\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        m.train()\n",
    "\n",
    "# Unfreeze last conv block + fc layer\n",
    "for name, p in model.named_parameters():\n",
    "    if \"layer3\" in name or \"layer4\" in name or \"fc\" in name:\n",
    "        p.requires_grad=True\n",
    "\n",
    "# Optimizer only for trainable params\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=3e-4)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=weights_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0a5b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]:   0%|          | 0/51 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Training the model (10 epochs)\n",
    "# Use tqmd for a progress bar\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 10\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # ---------- Training ----------\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Wrap train_loader with tqdm\n",
    "    train_iter = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\", leave=False)\n",
    "    for imgs, lbls in train_iter:\n",
    "        imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, lbls)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "        # Update tqdm description with current loss\n",
    "        train_iter.set_postfix(loss=loss.item())\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "\n",
    "    # ---------- Validation ----------\n",
    "    model.eval()\n",
    "    val_correct, val_total = 0, 0\n",
    "    val_iter = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in val_iter:\n",
    "            imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "            outputs = model(imgs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_correct += (preds == lbls).sum().item()\n",
    "            val_total += lbls.size(0)\n",
    "    \n",
    "    val_acc = val_correct / val_total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss:.4f} - Val Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    # Save the best model\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_painter_top3_resnet18.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
